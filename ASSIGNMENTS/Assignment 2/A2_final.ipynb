{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:29:00.636707Z","iopub.status.busy":"2024-08-09T19:29:00.636051Z","iopub.status.idle":"2024-08-09T19:29:06.462826Z","shell.execute_reply":"2024-08-09T19:29:06.461790Z","shell.execute_reply.started":"2024-08-09T19:29:00.636671Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Device: cuda\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","#models\n","import torch\n","from transformers import AutoTokenizer, AutoModel\n","from transformers import EvalPrediction\n","from torch.utils.data import DataLoader, Dataset\n","from torch.nn import BCEWithLogitsLoss\n","from torch.optim import Adam\n","\n","#metrics\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.metrics import roc_curve, auc\n","\n","from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","print(f\"Device: {device}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Task 1 - Corpus"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:29:11.116231Z","iopub.status.busy":"2024-08-09T19:29:11.115230Z","iopub.status.idle":"2024-08-09T19:29:11.123348Z","shell.execute_reply":"2024-08-09T19:29:11.122281Z","shell.execute_reply.started":"2024-08-09T19:29:11.116195Z"},"trusted":true},"outputs":[],"source":["def load_and_merge_data():\n","    \n","    #encodng the data into pandas.DataFrame objects\n","    url_a_test = '/kaggle/input/dataset/arguments-test.tsv'\n","    df_a_test = pd.read_csv(url_a_test, sep='\\t')\n","\n","    url_a_training = '/kaggle/input/dataset/arguments-training.tsv'\n","    df_a_training = pd.read_csv(url_a_training, sep='\\t')\n","\n","    url_a_validation = '/kaggle/input/dataset/arguments-validation.tsv'\n","    df_a_validation = pd.read_csv(url_a_validation, sep='\\t')\n","\n","    url_l_test = '/kaggle/input/dataset/labels-test.tsv'\n","    df_l_test = pd.read_csv(url_l_test, sep='\\t')\n","\n","    url_l_training = '/kaggle/input/dataset/labels-training.tsv'\n","    df_l_training = pd.read_csv(url_l_training, sep='\\t')\n","\n","    url_l_validation = '/kaggle/input/dataset/labels-validation.tsv'\n","    df_l_validation = pd.read_csv(url_l_validation, sep='\\t')\n","\n","    #merge argument dataframes with label dataframes\n","    df_test = pd.merge(df_a_test, df_l_test, on='Argument ID')\n","    df_training = pd.merge(df_a_training, df_l_training, on='Argument ID')\n","    df_validation = pd.merge(df_a_validation, df_l_validation, on='Argument ID')\n","\n","    return df_test, df_training, df_validation"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:29:16.313253Z","iopub.status.busy":"2024-08-09T19:29:16.312874Z","iopub.status.idle":"2024-08-09T19:29:16.445254Z","shell.execute_reply":"2024-08-09T19:29:16.444531Z","shell.execute_reply.started":"2024-08-09T19:29:16.313222Z"},"trusted":true},"outputs":[],"source":["df_test, df_training, df_validation = load_and_merge_data()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:29:21.902793Z","iopub.status.busy":"2024-08-09T19:29:21.901966Z","iopub.status.idle":"2024-08-09T19:29:21.936242Z","shell.execute_reply":"2024-08-09T19:29:21.935530Z","shell.execute_reply.started":"2024-08-09T19:29:21.902759Z"},"trusted":true},"outputs":[],"source":["def merge_and_drop_columns(df):\n","    # Merge level 2 annotations to level 3 categories\n","    df['Openess to change'] = df[['Self-direction: thought', 'Self-direction: action', 'Stimulation', 'Hedonism']].any(axis=1).astype(int)\n","    df['Self-enhancement'] = df[['Hedonism', 'Achievement', 'Power: dominance', 'Power: resources', 'Face']].any(axis=1).astype(int)\n","    df['Conservation'] = df[['Face', 'Security: personal', 'Security: societal', 'Tradition', 'Conformity: rules', 'Conformity: interpersonal', 'Humility']].any(axis=1).astype(int)\n","    df['Self-transcendence'] = df[['Humility', 'Benevolence: caring', 'Benevolence: dependability', 'Universalism: concern', 'Universalism: nature', 'Universalism: tolerance', 'Universalism: objectivity']].any(axis=1).astype(int)\n","    \n","    # Drop unuseful columns\n","    columns_to_drop = ['Argument ID', 'Self-direction: thought', 'Self-direction: action', 'Stimulation', 'Hedonism', 'Achievement', 'Power: dominance', 'Power: resources', 'Face', 'Security: personal', 'Security: societal', 'Tradition', 'Conformity: rules', 'Conformity: interpersonal', 'Humility', 'Benevolence: caring', 'Benevolence: dependability', 'Universalism: concern', 'Universalism: nature', 'Universalism: tolerance', 'Universalism: objectivity']\n","    df = df.drop(columns=columns_to_drop)\n","    \n","    return df\n","\n","df_test = merge_and_drop_columns(df_test)\n","df_training = merge_and_drop_columns(df_training)\n","df_validation = merge_and_drop_columns(df_validation)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:29:25.928809Z","iopub.status.busy":"2024-08-09T19:29:25.928101Z","iopub.status.idle":"2024-08-09T19:29:25.945368Z","shell.execute_reply":"2024-08-09T19:29:25.944287Z","shell.execute_reply.started":"2024-08-09T19:29:25.928776Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Conclusion</th>\n","      <th>Stance</th>\n","      <th>Premise</th>\n","      <th>Openess to change</th>\n","      <th>Self-enhancement</th>\n","      <th>Conservation</th>\n","      <th>Self-transcendence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>We should end affirmative action</td>\n","      <td>against</td>\n","      <td>affirmative action helps with employment equity.</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>We should end affirmative action</td>\n","      <td>in favor of</td>\n","      <td>affirmative action can be considered discrimin...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>We should ban naturopathy</td>\n","      <td>in favor of</td>\n","      <td>naturopathy is very dangerous for the most vul...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>We should prohibit women in combat</td>\n","      <td>in favor of</td>\n","      <td>women shouldn't be in combat because they aren...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>We should ban naturopathy</td>\n","      <td>in favor of</td>\n","      <td>once eradicated illnesses are returning due to...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                           Conclusion       Stance  \\\n","0    We should end affirmative action      against   \n","1    We should end affirmative action  in favor of   \n","2           We should ban naturopathy  in favor of   \n","3  We should prohibit women in combat  in favor of   \n","4           We should ban naturopathy  in favor of   \n","\n","                                             Premise  Openess to change  \\\n","0   affirmative action helps with employment equity.                  0   \n","1  affirmative action can be considered discrimin...                  0   \n","2  naturopathy is very dangerous for the most vul...                  0   \n","3  women shouldn't be in combat because they aren...                  0   \n","4  once eradicated illnesses are returning due to...                  0   \n","\n","   Self-enhancement  Conservation  Self-transcendence  \n","0                 1             1                   1  \n","1                 1             0                   1  \n","2                 1             1                   1  \n","3                 1             0                   0  \n","4                 1             1                   1  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df_test.head()"]},{"cell_type":"markdown","metadata":{},"source":["### DATA EXPLORATION\n","Ancora da inserire - sicuramente c'è da mettere una metrica per vedere la lunghezza dentro a conclusion, premise e stance per giustificare max length = 100\n","per il resto non saprei cosa altro mettere, se vuoi la presenza di in favor of e against della colonna stance nei vari dataset e altro"]},{"cell_type":"markdown","metadata":{},"source":["### DATA PREPROCESSING"]},{"cell_type":"markdown","metadata":{},"source":["Encoding 'Stance' column into numerical format  "]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:29:31.607060Z","iopub.status.busy":"2024-08-09T19:29:31.606481Z","iopub.status.idle":"2024-08-09T19:29:31.626462Z","shell.execute_reply":"2024-08-09T19:29:31.625404Z","shell.execute_reply.started":"2024-08-09T19:29:31.607028Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34/2140913224.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df_test['Stance'] = df_test['Stance'].replace({'in favor of': 1, 'against': 0}).astype(str)\n","/tmp/ipykernel_34/2140913224.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df_training['Stance'] = df_training['Stance'].replace({'in favor of': 1, 'against': 0}).astype(str)\n","/tmp/ipykernel_34/2140913224.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df_validation['Stance'] = df_validation['Stance'].replace({'in favor of': 1, 'against': 0}).astype(str)\n"]}],"source":["df_test['Stance'] = df_test['Stance'].replace({'in favor of': 1, 'against': 0}).astype(str)\n","df_training['Stance'] = df_training['Stance'].replace({'in favor of': 1, 'against': 0}).astype(str)\n","df_validation['Stance'] = df_validation['Stance'].replace({'in favor of': 1, 'against': 0}).astype(str)"]},{"cell_type":"markdown","metadata":{},"source":["Preparing data for tokenization input"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:29:36.265804Z","iopub.status.busy":"2024-08-09T19:29:36.264918Z","iopub.status.idle":"2024-08-09T19:29:36.273109Z","shell.execute_reply":"2024-08-09T19:29:36.272190Z","shell.execute_reply.started":"2024-08-09T19:29:36.265768Z"},"trusted":true},"outputs":[],"source":["labels_test = df_test.iloc[:, 3:7].values\n","labels_training = df_training.iloc[:, 3:7].values\n","labels_validation = df_validation.iloc[:, 3:7].values\n","\n","stance_test = df_test['Stance'].values\n","stance_training = df_training['Stance'].values\n","stance_validation = df_validation['Stance'].values"]},{"cell_type":"markdown","metadata":{},"source":["Tokenization process and creation of a dataset structure compatible with the bert model "]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:29:40.570348Z","iopub.status.busy":"2024-08-09T19:29:40.570020Z","iopub.status.idle":"2024-08-09T19:29:41.852065Z","shell.execute_reply":"2024-08-09T19:29:41.851134Z","shell.execute_reply.started":"2024-08-09T19:29:40.570310Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"229ce25e12b1405995c61791fa95729d","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75b5c9634f984e89b1bd390fc74ff8f7","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c9f1b8a5b84d4c2eabf28056cd2588f8","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1816111028d44c15a8e99bac7612ce9b","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","max_length = 100\n","\n","class BertDatasetCreator(Dataset):\n","    def __init__(self, encodings, labels, tokenizer, max_length):\n","        self.encodings = encodings\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","    \n","    def __len__(self):\n","        return len(self.encodings)\n","    \n","    def __getitem__(self, idx):\n","        item = str(self.encodings[idx])\n","        item = ' '.join(item.split())\n","        \n","        encoded_dict = self.tokenizer.encode_plus(\n","            item,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            return_token_type_ids=True,\n","            truncation=True,\n","        )\n","        input_ids = encoded_dict['input_ids']\n","        attention_masks = encoded_dict['attention_mask']\n","        token_type_ids = encoded_dict['token_type_ids']\n","\n","        return {\n","            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n","            'attention_mask': torch.tensor(attention_masks, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'labels': torch.tensor(self.labels[idx], dtype=torch.float)\n","        }"]},{"cell_type":"markdown","metadata":{},"source":["#### Applying the BertDatasetCreator and preparing the datasets for the three different type of BERT models"]},{"cell_type":"markdown","metadata":{},"source":["##### BERT w/C dataset"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:29:45.760158Z","iopub.status.busy":"2024-08-09T19:29:45.759352Z","iopub.status.idle":"2024-08-09T19:29:45.765203Z","shell.execute_reply":"2024-08-09T19:29:45.763985Z","shell.execute_reply.started":"2024-08-09T19:29:45.760129Z"},"trusted":true},"outputs":[],"source":["test_dataset_c = BertDatasetCreator(df_test['Conclusion'], labels_test, tokenizer, max_length)\n","train_dataset_c = BertDatasetCreator(df_training['Conclusion'], labels_training, tokenizer, max_length)\n","val_dataset_c = BertDatasetCreator(df_validation['Conclusion'], labels_validation, tokenizer, max_length)"]},{"cell_type":"markdown","metadata":{},"source":["DataLoader definition - which will supply the data to the neural network in batches for efficient training and processing"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:29:54.382498Z","iopub.status.busy":"2024-08-09T19:29:54.382128Z","iopub.status.idle":"2024-08-09T19:29:54.387736Z","shell.execute_reply":"2024-08-09T19:29:54.386354Z","shell.execute_reply.started":"2024-08-09T19:29:54.382467Z"},"trusted":true},"outputs":[],"source":["batch_size = 16\n","test_dataloader_c = DataLoader(test_dataset_c, batch_size=batch_size)\n","train_dataloader_c = DataLoader(train_dataset_c, batch_size=batch_size)\n","val_dataloader_c = DataLoader(val_dataset_c, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["##### BERT w/CP"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:29:57.944806Z","iopub.status.busy":"2024-08-09T19:29:57.944164Z","iopub.status.idle":"2024-08-09T19:29:57.954771Z","shell.execute_reply":"2024-08-09T19:29:57.953896Z","shell.execute_reply.started":"2024-08-09T19:29:57.944773Z"},"trusted":true},"outputs":[],"source":["test_dataset_cp = BertDatasetCreator(df_test['Conclusion'] + ' ' + df_test['Premise'], labels_test, tokenizer, max_length)\n","train_dataset_cp = BertDatasetCreator(df_training['Conclusion'] + ' ' + df_training['Premise'], labels_training, tokenizer, max_length)\n","val_dataset_cp = BertDatasetCreator(df_validation['Conclusion'] + ' ' + df_validation['Premise'], labels_validation, tokenizer, max_length)\n","\n","test_dataloader_cp = DataLoader(test_dataset_cp, batch_size=batch_size)\n","train_dataloader_cp = DataLoader(train_dataset_cp, batch_size=batch_size)\n","val_dataloader_cp = DataLoader(val_dataset_cp, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["##### BERT w/CPS"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:30:01.544043Z","iopub.status.busy":"2024-08-09T19:30:01.543210Z","iopub.status.idle":"2024-08-09T19:30:01.557998Z","shell.execute_reply":"2024-08-09T19:30:01.556826Z","shell.execute_reply.started":"2024-08-09T19:30:01.544012Z"},"trusted":true},"outputs":[],"source":["test_dataset_cps = BertDatasetCreator(df_test['Conclusion'] + ' ' + df_test['Premise'] + ' ' + df_test['Stance'], labels_test, tokenizer, max_length)\n","train_dataset_cps = BertDatasetCreator(df_training['Conclusion'] + ' ' + df_training['Premise'] + ' ' + df_training['Stance'], labels_training, tokenizer, max_length)\n","val_dataset_cps = BertDatasetCreator(df_validation['Conclusion'] + ' ' + df_validation['Premise'] + ' ' + df_validation['Stance'], labels_validation, tokenizer, max_length)\n","\n","test_dataloader_cps = DataLoader(test_dataset_cps, batch_size=batch_size)\n","train_dataloader_cps = DataLoader(train_dataset_cps, batch_size=batch_size)\n","val_dataloader_cps = DataLoader(val_dataset_cps, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["## Task 2 - Models Definitions"]},{"cell_type":"markdown","metadata":{},"source":["### BASELINE MODELS"]},{"cell_type":"markdown","metadata":{},"source":["Random uniform classifier"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:30:06.320654Z","iopub.status.busy":"2024-08-09T19:30:06.320259Z","iopub.status.idle":"2024-08-09T19:30:06.325493Z","shell.execute_reply":"2024-08-09T19:30:06.324538Z","shell.execute_reply.started":"2024-08-09T19:30:06.320623Z"},"trusted":true},"outputs":[],"source":["def create_random_uniform_classifier(label):\n","    def random_uniform_classifier(size):\n","        return np.random.choice([0, 1], size=size)\n","    return random_uniform_classifier"]},{"cell_type":"markdown","metadata":{},"source":["Majority classifier - always predicting the most frequent valorization for the column"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:30:10.960221Z","iopub.status.busy":"2024-08-09T19:30:10.959902Z","iopub.status.idle":"2024-08-09T19:30:10.965762Z","shell.execute_reply":"2024-08-09T19:30:10.964839Z","shell.execute_reply.started":"2024-08-09T19:30:10.960198Z"},"trusted":true},"outputs":[],"source":["def create_majority_classifier(label, train_data):\n","    # Calcola il majority_value come la moda della colonna corrispondente alla label nel dataset di train\n","    majority_value = train_data[label].mode()[0]\n","    def majority_classifier(size):\n","        return np.full(size, majority_value)\n","    return majority_classifier"]},{"cell_type":"markdown","metadata":{},"source":["Creating the baseline models for every category and saving them in a classifiers dictionary"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:30:14.651628Z","iopub.status.busy":"2024-08-09T19:30:14.650808Z","iopub.status.idle":"2024-08-09T19:30:14.658191Z","shell.execute_reply":"2024-08-09T19:30:14.657167Z","shell.execute_reply.started":"2024-08-09T19:30:14.651580Z"},"trusted":true},"outputs":[],"source":["classifiers = {}\n","\n","labels = ['Openess to change', 'Self-enhancement', 'Conservation', 'Self-transcendence']\n","\n","#create classifiers for each category and save them in the dictionary\n","for label in labels:\n","    #random uniform classifier\n","    random_uniform_name = f'random_uniform_classifier_{label}'\n","    classifiers[random_uniform_name] = create_random_uniform_classifier(label)\n","\n","    #majority classifier\n","    majority_name = f'majority_classifier_{label}'\n","    classifiers[majority_name] = create_majority_classifier(label, df_training)"]},{"cell_type":"markdown","metadata":{},"source":["### BERT Model Definition"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:30:19.037631Z","iopub.status.busy":"2024-08-09T19:30:19.036805Z","iopub.status.idle":"2024-08-09T19:30:19.046875Z","shell.execute_reply":"2024-08-09T19:30:19.045599Z","shell.execute_reply.started":"2024-08-09T19:30:19.037581Z"},"trusted":true},"outputs":[],"source":["class Bert_Model(torch.nn.Module):\n","    def __init__(self):\n","        super(Bert_Model, self).__init__()\n","        self.bert = AutoModel.from_pretrained(\n","            pretrained_model_name_or_path= 'bert-base-uncased', \n","            problem_type='multi_label_classification', \n","            num_labels = 4, \n","            return_dict=False)\n","        self.dropout = torch.nn.Dropout(p=0.3)\n","        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, 4)\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        _, outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        outputs = self.dropout(outputs)\n","        outputs = self.classifier(outputs)\n","        return outputs"]},{"cell_type":"markdown","metadata":{},"source":["#### Bert Models"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:30:23.530596Z","iopub.status.busy":"2024-08-09T19:30:23.529616Z","iopub.status.idle":"2024-08-09T19:30:27.664758Z","shell.execute_reply":"2024-08-09T19:30:27.663774Z","shell.execute_reply.started":"2024-08-09T19:30:23.530558Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"feaa096ed99a4f6084e84a7845f8fe95","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["Bert_Model(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",")"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["c_model = Bert_Model()\n","cp_model = Bert_Model()\n","cps_model = Bert_Model()\n","\n","c_model.to(device)\n","cp_model.to(device)\n","cps_model.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["## Task 3 - Metrics"]},{"cell_type":"markdown","metadata":{},"source":["### Baseline models metrics function"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def baseline_metrics(predicted_results, test_dataset, labels):\n","    f1_scores = {}\n","    binary_f1_scores = []\n","    for label in labels:\n","        true_values = test_dataset[label]\n","        predictions = predicted_results[label]\n","        f1 = f1_score(true_values, predictions, average='binary')\n","        f1 = round(f1, 2) #round to 2 decimal places\n","        f1_score_name = f'{label} F1: '\n","        f1_scores[f1_score_name] = f1\n","\n","        #binary f1 score for every category\n","        binary_f1 = f1_score(true_values, predictions, average='binary')\n","        binary_f1_scores.append(binary_f1)\n","\n","     #macro f1 score\n","    macro_f1 = round(np.mean(binary_f1_scores), 2)\n","    f1_scores['macro_f1: '] = macro_f1\n","    return f1_scores"]},{"cell_type":"markdown","metadata":{},"source":["Baseline models metrics printing function"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def print_baseline_metrics(metrics, type):\n","    if type == 'random_uniform':\n","        classifier_type = 'Random Uniform'\n","    elif type == 'majority':\n","        classifier_type = 'Majority'\n","    print(f\"Classifier Type: {classifier_type}\")\n","    for label, score in metrics.items():\n","        print(f\"{label}: {score}\")"]},{"cell_type":"markdown","metadata":{},"source":["### BERT models metrics function"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:31:18.132204Z","iopub.status.busy":"2024-08-09T19:31:18.131229Z","iopub.status.idle":"2024-08-09T19:31:18.143505Z","shell.execute_reply":"2024-08-09T19:31:18.142648Z","shell.execute_reply.started":"2024-08-09T19:31:18.132170Z"},"trusted":true},"outputs":[],"source":["def generate_classification_report(model, X_test, Y_test, thresholds):\n","    \n","    # Mettere il modello in modalità di valutazione\n","    model.eval()\n","    Y_pred = []\n","    num_labels = len(thresholds)\n","    \n","    with torch.no_grad():# Disabilitare il calcolo dei gradienti per la valutazione\n","        for _, batch in enumerate(X_test, 0):\n","            input_ids = batch['input_ids'].to(device, dtype = torch.long)\n","            attention_mask = batch['attention_mask'].to(device, dtype = torch.long)\n","            token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n","            #labels = batch['labels'].to(device, dtype = torch.long)\n","            \n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","            \n","            # Spostare il tensore degli output sulla CPU e convertirlo in un array NumPy\n","            outputs = outputs.cpu().numpy()\n","\n","        # Applica le soglie ottimali per ottenere le previsioni binarie\n","            preds = np.zeros_like(outputs)\n","            for i in range(num_labels):\n","                preds[:, i] = (outputs[:, i] > thresholds[i]).astype(int)\n","            Y_pred.extend(preds)\n","            \n","    Y_pred = np.array(Y_pred)\n","    '''\n","    # Convertire Y_test in array multiclass se è multilabel\n","    if len(Y_test.shape) > 1 and Y_test.shape[1] > 1:\n","        Y_test = np.argmax(Y_test, axis=1)\n","    '''\n","    \n","    # Generare il classification report\n","    report = classification_report(Y_test, Y_pred, zero_division=1, output_dict=True)\n","    \n","    # Mappatura delle labels\n","    label_names = {\n","        '0': \"Openness to change\",\n","        '1': \"Self-enhancement\",\n","        '2': \"Conservation\",\n","        '3': \"Self-transcendence\"\n","    }\n","    \n","    # Estrarre e stampare l'F1 score per ogni etichetta\n","    print(\"\\nF1 Scores per Label:\")\n","    for label, metrics in report.items():\n","        if label not in ['accuracy', 'macro avg', 'weighted avg']:\n","            label_name = label_names.get(label, f\"Label {label}\")\n","            f1_score = metrics['f1-score']\n","            print(f\"{label_name} F1: = {f1_score:.2f}\")\n","    \n","    # Estrarre e stampare il macro F1 score\n","    macro_f1_score = report['macro avg']['f1-score']\n","    print(f\"Macro F1 Score: {macro_f1_score:.2f}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Task 4 - Training and evaluation"]},{"cell_type":"markdown","metadata":{},"source":["## Baseline models training and metrics"]},{"cell_type":"markdown","metadata":{},"source":["### Random uniform classifiers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def random_uniform_classifiers(classifiers, test_dataset, labels):\n","    predicted_results = {}\n","\n","    for label in labels:\n","        random_uniform_name = f'random_uniform_classifier_{label}'\n","        classifier = classifiers[random_uniform_name]\n","        test_data = test_dataset[label]\n","        size = len(test_data)\n","        predictions = classifier(size)\n","        predicted_results[label] = predictions\n","\n","    return predicted_results"]},{"cell_type":"markdown","metadata":{},"source":["Metrics for the random uniform classifiers - F1 score for each category and macro F1 score "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["metrics_random_uniform = baseline_metrics(random_uniform_classifiers(classifiers, df_test, labels), df_test, labels)\n","print_baseline_metrics(metrics_random_uniform, 'random_uniform')"]},{"cell_type":"markdown","metadata":{},"source":["### Majority classifiers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def majority_classifiers(classifiers, test_dataset, labels):\n","    predicted_results = {}\n","\n","    for label in labels:\n","        majority_name = f'majority_classifier_{label}'\n","        classifier = classifiers[majority_name]\n","        test_data = test_dataset[label]\n","        size = len(test_data)\n","        predictions = classifier(size)\n","        predicted_results[label] = predictions\n","\n","    return predicted_results"]},{"cell_type":"markdown","metadata":{},"source":["Metrics for the majority classifiers - F1 score for each category and macro F1 score "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["metrics_majority = baseline_metrics(majority_classifiers(classifiers, df_test, labels), df_test, labels)\n","print_baseline_metrics(metrics_majority, 'majority')"]},{"cell_type":"markdown","metadata":{},"source":["## BERT model training and evaluation"]},{"cell_type":"markdown","metadata":{},"source":["Training process utils"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:31:25.083703Z","iopub.status.busy":"2024-08-09T19:31:25.083344Z","iopub.status.idle":"2024-08-09T19:31:25.733411Z","shell.execute_reply":"2024-08-09T19:31:25.732614Z","shell.execute_reply.started":"2024-08-09T19:31:25.083676Z"},"trusted":true},"outputs":[],"source":["#definition of the loss function\n","def loss_function(outputs, targets):\n","    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n","\n","#definition of the optimizers\n","optimizer = Adam(c_model.parameters(), lr = 1e-5)\n","\n","# Set seeds for reproducibility\n","def set_seed(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","\n","seeds = [42, 123, 2024]\n","epochs = 5"]},{"cell_type":"markdown","metadata":{},"source":["#### Training function definition"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:31:29.765777Z","iopub.status.busy":"2024-08-09T19:31:29.765190Z","iopub.status.idle":"2024-08-09T19:31:29.774401Z","shell.execute_reply":"2024-08-09T19:31:29.773394Z","shell.execute_reply.started":"2024-08-09T19:31:29.765744Z"},"trusted":true},"outputs":[],"source":["def trainBert(model, dataloader, optimizer, loss_function):\n","    model.train()\n","    running_loss = 0.0\n","    for _, data in enumerate(dataloader, 0):\n","        ids = data['input_ids'].to(device, dtype=torch.long)\n","        mask = data['attention_mask'].to(device, dtype=torch.long)\n","        token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n","        labels = data['labels'].to(device)\n","        optimizer.zero_grad()\n","        outputs = model(ids, mask, token_type_ids)\n","    \n","        loss_value = loss_function(outputs, labels)\n","        loss_value.backward()\n","        optimizer.step()\n","        running_loss += loss_value.item()\n","        avg_train_loss = running_loss / len(dataloader)\n","    \n","    return avg_train_loss"]},{"cell_type":"markdown","metadata":{},"source":["#### Validation function definition"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:31:35.339501Z","iopub.status.busy":"2024-08-09T19:31:35.339112Z","iopub.status.idle":"2024-08-09T19:31:35.351250Z","shell.execute_reply":"2024-08-09T19:31:35.350312Z","shell.execute_reply.started":"2024-08-09T19:31:35.339469Z"},"trusted":true},"outputs":[],"source":["def validate_model(model, dataloader):\n","    model.eval()\n","    all_labels = []\n","    all_outputs = []\n","\n","    with torch.no_grad():\n","        for batch_idx, data in enumerate(dataloader, 0):\n","            input_ids = data['input_ids'].to(device, dtype = torch.long)\n","            attention_mask = data['attention_mask'].to(device, dtype = torch.long)\n","            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","            labels = data['labels'].to(device, dtype = torch.float)\n","            outputs = model(input_ids, attention_mask, token_type_ids)\n","            all_labels.extend(labels.cpu().numpy())\n","            all_outputs.extend(outputs.cpu().numpy())\n","\n","    all_labels = np.array(all_labels)\n","    all_outputs = np.array(all_outputs)\n","\n","    # Numero di etichette\n","    num_labels = all_labels.shape[1]\n","\n","    # Inizializza una lista per memorizzare le soglie ottimali per ogni etichetta\n","    optimal_thresholds = []\n","    auc_scores = []\n","\n","    for i in range(num_labels):\n","        # Calcola la curva ROC\n","        fpr, tpr, thresholds = roc_curve(all_labels[:, i], all_outputs[:, i])\n","        # Calcola l'AUC\n","        roc_auc = auc(fpr, tpr)\n","        auc_scores.append(roc_auc)\n","        # Trova la soglia che massimizza la somma di sensibilità e specificità\n","        optimal_idx = np.argmax(tpr - fpr)\n","        optimal_threshold = thresholds[optimal_idx]\n","        optimal_thresholds.append(optimal_threshold)\n","\n","    # Applica le soglie ottimali per ottenere le previsioni binarie\n","    all_preds = np.zeros_like(all_outputs)\n","    for i in range(num_labels):\n","        all_preds[:, i] = (all_outputs[:, i] > optimal_thresholds[i]).astype(int)\n","\n","    accuracy = accuracy_score(all_labels, all_preds)\n","    precision = precision_score(all_labels, all_preds, average='weighted')\n","    recall = recall_score(all_labels, all_preds, average='weighted')\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","    return accuracy, precision, recall, f1, optimal_thresholds\n"]},{"cell_type":"markdown","metadata":{},"source":["### Training and evaluating BERT w/C"]},{"cell_type":"markdown","metadata":{},"source":["Defining a dictionary to store all the classification reports - one for each model per seed. "]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:31:40.888049Z","iopub.status.busy":"2024-08-09T19:31:40.887703Z","iopub.status.idle":"2024-08-09T19:31:40.892455Z","shell.execute_reply":"2024-08-09T19:31:40.891246Z","shell.execute_reply.started":"2024-08-09T19:31:40.888019Z"},"trusted":true},"outputs":[],"source":["classification_reports = {}"]},{"cell_type":"markdown","metadata":{},"source":["Training, evaluation and metrics "]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:31:45.279999Z","iopub.status.busy":"2024-08-09T19:31:45.279136Z","iopub.status.idle":"2024-08-09T19:57:49.201811Z","shell.execute_reply":"2024-08-09T19:57:49.200703Z","shell.execute_reply.started":"2024-08-09T19:31:45.279963Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Seed 42\n","-------------------------------\n","\n","Epoch 1\n","-------------------------------\n","Average Train Loss: 0.5964\n","Validation - Accuracy: 0.0628, Precision: 0.7128, Recall: 0.5429, F1 Score: 0.5645\n","\n","Epoch 2\n","-------------------------------\n","Average Train Loss: 0.5639\n","Validation - Accuracy: 0.1756, Precision: 0.7552, Recall: 0.6002, F1 Score: 0.6676\n","\n","Epoch 3\n","-------------------------------\n","Average Train Loss: 0.5530\n","Validation - Accuracy: 0.2104, Precision: 0.7559, Recall: 0.6359, F1 Score: 0.6899\n","\n","Epoch 4\n","-------------------------------\n","Average Train Loss: 0.5464\n","Validation - Accuracy: 0.1519, Precision: 0.7429, Recall: 0.5581, F1 Score: 0.6270\n","\n","Epoch 5\n","-------------------------------\n","Average Train Loss: 0.5432\n","Validation - Accuracy: 0.2104, Precision: 0.7577, Recall: 0.6053, F1 Score: 0.6711\n","\n","Classification report \n","-------------------------------\n","\n","F1 Scores per Label:\n","Openness to change F1: = 0.05\n","Self-enhancement F1: = 0.19\n","Conservation F1: = 0.64\n","Self-transcendence F1: = 0.77\n","Label micro avg F1: = 0.57\n","Label samples avg F1: = 0.54\n","Macro F1 Score: 0.41\n","\n","Seed 123\n","-------------------------------\n","\n","Epoch 1\n","-------------------------------\n","Average Train Loss: 0.5381\n","Validation - Accuracy: 0.2147, Precision: 0.7557, Recall: 0.6281, F1 Score: 0.6830\n","\n","Epoch 2\n","-------------------------------\n","Average Train Loss: 0.5362\n","Validation - Accuracy: 0.1835, Precision: 0.7569, Recall: 0.5449, F1 Score: 0.6276\n","\n","Epoch 3\n","-------------------------------\n","Average Train Loss: 0.5337\n","Validation - Accuracy: 0.1962, Precision: 0.7615, Recall: 0.5770, F1 Score: 0.6521\n","\n","Epoch 4\n","-------------------------------\n","Average Train Loss: 0.5310\n","Validation - Accuracy: 0.1355, Precision: 0.7473, Recall: 0.5976, F1 Score: 0.6533\n","\n","Epoch 5\n","-------------------------------\n","Average Train Loss: 0.5300\n","Validation - Accuracy: 0.1303, Precision: 0.7490, Recall: 0.6133, F1 Score: 0.6600\n","\n","Classification report \n","-------------------------------\n","\n","F1 Scores per Label:\n","Openness to change F1: = 0.48\n","Self-enhancement F1: = 0.40\n","Conservation F1: = 0.25\n","Self-transcendence F1: = 0.70\n","Label micro avg F1: = 0.49\n","Label samples avg F1: = 0.46\n","Macro F1 Score: 0.46\n","\n","Seed 2024\n","-------------------------------\n","\n","Epoch 1\n","-------------------------------\n","Average Train Loss: 0.5281\n","Validation - Accuracy: 0.1181, Precision: 0.7410, Recall: 0.5865, F1 Score: 0.6413\n","\n","Epoch 2\n","-------------------------------\n","Average Train Loss: 0.5270\n","Validation - Accuracy: 0.0934, Precision: 0.7349, Recall: 0.5637, F1 Score: 0.6179\n","\n","Epoch 3\n","-------------------------------\n","Average Train Loss: 0.5250\n","Validation - Accuracy: 0.1313, Precision: 0.7344, Recall: 0.6478, F1 Score: 0.6742\n","\n","Epoch 4\n","-------------------------------\n","Average Train Loss: 0.5236\n","Validation - Accuracy: 0.1350, Precision: 0.7500, Recall: 0.6100, F1 Score: 0.6631\n","\n","Epoch 5\n","-------------------------------\n","Average Train Loss: 0.5241\n","Validation - Accuracy: 0.1535, Precision: 0.7443, Recall: 0.6662, F1 Score: 0.6917\n","\n","Classification report \n","-------------------------------\n","\n","F1 Scores per Label:\n","Openness to change F1: = 0.46\n","Self-enhancement F1: = 0.20\n","Conservation F1: = 0.35\n","Self-transcendence F1: = 0.82\n","Label micro avg F1: = 0.54\n","Label samples avg F1: = 0.51\n","Macro F1 Score: 0.46\n"]}],"source":["for seed in seeds:\n","    set_seed(seed)\n","    print(f'\\nSeed {seed}\\n-------------------------------')\n","    for epoch in range(epochs):\n","        #training\n","        print(f\"\\nEpoch {epoch + 1}\\n-------------------------------\")\n","        avg_train_loss = trainBert(c_model, train_dataloader_c, optimizer, loss_function)\n","        print(f'Average Train Loss: {avg_train_loss:.4f}')\n","        #validation\n","        accuracy, precision, recall, f1, c_thresholds = validate_model(c_model, val_dataloader_c)\n","        print(f'Validation - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n","    #generate classification-report\n","    print(f'\\nClassification report \\n-------------------------------')\n","    classification_report_name = f'classification_report_c_model_{seed}'\n","    classification_reports[classification_report_name] = generate_classification_report(c_model, test_dataloader_c, labels_test, c_thresholds)\n","    \n","    torch.save(c_model.state_dict(), f'c_model_{seed}.pth')"]},{"cell_type":"markdown","metadata":{},"source":["### Training and evaluating BERT w/CP"]},{"cell_type":"markdown","metadata":{},"source":["Training, evaluation and metrics "]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T19:58:13.428243Z","iopub.status.busy":"2024-08-09T19:58:13.427883Z","iopub.status.idle":"2024-08-09T20:22:25.555698Z","shell.execute_reply":"2024-08-09T20:22:25.554836Z","shell.execute_reply.started":"2024-08-09T19:58:13.428210Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Seed 42\n","-------------------------------\n","\n","Epoch 1\n","-------------------------------\n","Loss: 0.7450\n","Validation - Accuracy: 0.0432, Precision: 0.6771, Recall: 0.5116, F1 Score: 0.4484\n","\n","Epoch 2\n","-------------------------------\n","Loss: 0.7431\n","Validation - Accuracy: 0.0432, Precision: 0.6771, Recall: 0.5116, F1 Score: 0.4484\n","\n","Epoch 3\n","-------------------------------\n","Loss: 0.7436\n","Validation - Accuracy: 0.0432, Precision: 0.6771, Recall: 0.5116, F1 Score: 0.4484\n","\n","Epoch 4\n","-------------------------------\n","Loss: 0.7443\n","Validation - Accuracy: 0.0432, Precision: 0.6771, Recall: 0.5116, F1 Score: 0.4484\n","\n","Epoch 5\n","-------------------------------\n","Loss: 0.7438\n","Validation - Accuracy: 0.0432, Precision: 0.6771, Recall: 0.5116, F1 Score: 0.4484\n","\n","Classification report \n","-------------------------------\n","\n","F1 Scores per Label:\n","Openness to change F1: = 0.40\n","Self-enhancement F1: = 0.56\n","Conservation F1: = 0.76\n","Self-transcendence F1: = 0.04\n","Label micro avg F1: = 0.50\n","Label samples avg F1: = 0.46\n","Macro F1 Score: 0.44\n","\n","Seed 123\n","-------------------------------\n","\n","Epoch 1\n","-------------------------------\n","Loss: 0.7436\n","Validation - Accuracy: 0.0432, Precision: 0.6771, Recall: 0.5116, F1 Score: 0.4484\n","\n","Epoch 2\n","-------------------------------\n","Loss: 0.7441\n","Validation - Accuracy: 0.0432, Precision: 0.6771, Recall: 0.5116, F1 Score: 0.4484\n","\n","Epoch 3\n","-------------------------------\n","Loss: 0.7445\n","Validation - Accuracy: 0.0432, Precision: 0.6771, Recall: 0.5116, F1 Score: 0.4484\n","\n","Epoch 4\n","-------------------------------\n","Loss: 0.7451\n","Validation - Accuracy: 0.0432, Precision: 0.6771, Recall: 0.5116, F1 Score: 0.4484\n","\n","Epoch 5\n","-------------------------------\n","Loss: 0.7449\n","Validation - Accuracy: 0.0432, Precision: 0.6771, Recall: 0.5116, F1 Score: 0.4484\n","\n","Classification report \n","-------------------------------\n","\n","F1 Scores per Label:\n","Openness to change F1: = 0.40\n","Self-enhancement F1: = 0.56\n","Conservation F1: = 0.76\n","Self-transcendence F1: = 0.04\n","Label micro avg F1: = 0.50\n","Label samples avg F1: = 0.46\n","Macro F1 Score: 0.44\n","\n","Seed 2024\n","-------------------------------\n","\n","Epoch 1\n","-------------------------------\n","Loss: 0.7448\n","Validation - Accuracy: 0.0432, Precision: 0.6771, Recall: 0.5116, F1 Score: 0.4484\n","\n","Epoch 2\n","-------------------------------\n","Loss: 0.7455\n","Validation - Accuracy: 0.0432, Precision: 0.6771, Recall: 0.5116, F1 Score: 0.4484\n","\n","Epoch 3\n","-------------------------------\n","Loss: 0.7449\n","Validation - Accuracy: 0.0432, Precision: 0.6771, Recall: 0.5116, F1 Score: 0.4484\n","\n","Epoch 4\n","-------------------------------\n","Loss: 0.7441\n","Validation - Accuracy: 0.0432, Precision: 0.6771, Recall: 0.5116, F1 Score: 0.4484\n","\n","Epoch 5\n","-------------------------------\n","Loss: 0.7449\n","Validation - Accuracy: 0.0432, Precision: 0.6771, Recall: 0.5116, F1 Score: 0.4484\n","\n","Classification report \n","-------------------------------\n","\n","F1 Scores per Label:\n","Openness to change F1: = 0.40\n","Self-enhancement F1: = 0.56\n","Conservation F1: = 0.76\n","Self-transcendence F1: = 0.04\n","Label micro avg F1: = 0.50\n","Label samples avg F1: = 0.46\n","Macro F1 Score: 0.44\n"]}],"source":["for seed in seeds:\n","    set_seed(seed)\n","    print(f'\\nSeed {seed}\\n-------------------------------')\n","    for epoch in range(epochs):\n","        print(f\"\\nEpoch {epoch + 1}\\n-------------------------------\")\n","        avg_train_loss = trainBert(cp_model, train_dataloader_cp, optimizer, loss_function)\n","        print(f'Loss: {avg_train_loss:.4f}')\n","        #validation\n","        accuracy, precision, recall, f1, cp_thresholds = validate_model(cp_model, val_dataloader_cp)\n","        print(f'Validation - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n","    #generate classification-report\n","    print(f'\\nClassification report \\n-------------------------------')\n","    classification_report_name = f'classification_report_cp_model_{seed}'\n","    classification_reports[classification_report_name] = generate_classification_report(cp_model, test_dataloader_cp, labels_test, cp_thresholds)\n","    \n","    torch.save(cp_model.state_dict(), f'cp_model_{seed}.pth')"]},{"cell_type":"markdown","metadata":{},"source":["### Training and evaluating BERT w/CPS"]},{"cell_type":"markdown","metadata":{},"source":["Training, evaluation and metrics "]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-08-09T20:22:45.738008Z","iopub.status.busy":"2024-08-09T20:22:45.737165Z","iopub.status.idle":"2024-08-09T20:46:59.720092Z","shell.execute_reply":"2024-08-09T20:46:59.719207Z","shell.execute_reply.started":"2024-08-09T20:22:45.737972Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Seed 42\n","-------------------------------\n","\n","Epoch 1\n","-------------------------------\n","Loss: 0.6833\n","Validation - Accuracy: 0.0654, Precision: 0.6881, Recall: 0.5905, F1 Score: 0.5471\n","\n","Epoch 2\n","-------------------------------\n","Loss: 0.6828\n","Validation - Accuracy: 0.0654, Precision: 0.6881, Recall: 0.5905, F1 Score: 0.5471\n","\n","Epoch 3\n","-------------------------------\n","Loss: 0.6815\n","Validation - Accuracy: 0.0654, Precision: 0.6881, Recall: 0.5905, F1 Score: 0.5471\n","\n","Epoch 4\n","-------------------------------\n","Loss: 0.6818\n","Validation - Accuracy: 0.0654, Precision: 0.6881, Recall: 0.5905, F1 Score: 0.5471\n","\n","Epoch 5\n","-------------------------------\n","Loss: 0.6834\n","Validation - Accuracy: 0.0654, Precision: 0.6881, Recall: 0.5905, F1 Score: 0.5471\n","\n","Classification report \n","-------------------------------\n","\n","F1 Scores per Label:\n","Openness to change F1: = 0.46\n","Self-enhancement F1: = 0.03\n","Conservation F1: = 0.34\n","Self-transcendence F1: = 0.88\n","Label micro avg F1: = 0.56\n","Label samples avg F1: = 0.54\n","Macro F1 Score: 0.43\n","Seed 123\n","-------------------------------\n","\n","Epoch 1\n","-------------------------------\n","Loss: 0.6835\n","Validation - Accuracy: 0.0654, Precision: 0.6881, Recall: 0.5905, F1 Score: 0.5471\n","\n","Epoch 2\n","-------------------------------\n","Loss: 0.6818\n","Validation - Accuracy: 0.0654, Precision: 0.6881, Recall: 0.5905, F1 Score: 0.5471\n","\n","Epoch 3\n","-------------------------------\n","Loss: 0.6828\n","Validation - Accuracy: 0.0654, Precision: 0.6881, Recall: 0.5905, F1 Score: 0.5471\n","\n","Epoch 4\n","-------------------------------\n","Loss: 0.6835\n","Validation - Accuracy: 0.0654, Precision: 0.6881, Recall: 0.5905, F1 Score: 0.5471\n","\n","Epoch 5\n","-------------------------------\n","Loss: 0.6844\n","Validation - Accuracy: 0.0654, Precision: 0.6881, Recall: 0.5905, F1 Score: 0.5471\n","\n","Classification report \n","-------------------------------\n","\n","F1 Scores per Label:\n","Openness to change F1: = 0.46\n","Self-enhancement F1: = 0.03\n","Conservation F1: = 0.34\n","Self-transcendence F1: = 0.88\n","Label micro avg F1: = 0.56\n","Label samples avg F1: = 0.54\n","Macro F1 Score: 0.43\n","Seed 2024\n","-------------------------------\n","\n","Epoch 1\n","-------------------------------\n","Loss: 0.6830\n","Validation - Accuracy: 0.0654, Precision: 0.6881, Recall: 0.5905, F1 Score: 0.5471\n","\n","Epoch 2\n","-------------------------------\n","Loss: 0.6835\n","Validation - Accuracy: 0.0654, Precision: 0.6881, Recall: 0.5905, F1 Score: 0.5471\n","\n","Epoch 3\n","-------------------------------\n","Loss: 0.6820\n","Validation - Accuracy: 0.0654, Precision: 0.6881, Recall: 0.5905, F1 Score: 0.5471\n","\n","Epoch 4\n","-------------------------------\n","Loss: 0.6828\n","Validation - Accuracy: 0.0654, Precision: 0.6881, Recall: 0.5905, F1 Score: 0.5471\n","\n","Epoch 5\n","-------------------------------\n","Loss: 0.6833\n","Validation - Accuracy: 0.0654, Precision: 0.6881, Recall: 0.5905, F1 Score: 0.5471\n","\n","Classification report \n","-------------------------------\n","\n","F1 Scores per Label:\n","Openness to change F1: = 0.46\n","Self-enhancement F1: = 0.03\n","Conservation F1: = 0.34\n","Self-transcendence F1: = 0.88\n","Label micro avg F1: = 0.56\n","Label samples avg F1: = 0.54\n","Macro F1 Score: 0.43\n"]}],"source":["for seed in seeds:\n","    set_seed(seed)\n","    print(f'Seed {seed}\\n-------------------------------')\n","    for epoch in range(epochs):\n","        print(f\"\\nEpoch {epoch + 1}\\n-------------------------------\")\n","        avg_train_loss = trainBert(cps_model, train_dataloader_cps, optimizer, loss_function)\n","        print(f'Loss: {avg_train_loss:.4f}')\n","        #validation\n","        accuracy, precision, recall, f1, cps_thresholds = validate_model(cps_model, val_dataloader_cps)\n","        print(f'Validation - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n","    #generate classification-report\n","    print(f'\\nClassification report \\n-------------------------------')\n","    classification_report_name = f'classification_report_cps_model_{seed}'\n","    classification_reports[classification_report_name] = generate_classification_report(cps_model, test_dataloader_cps, labels_test, cps_thresholds)\n","    \n","    torch.save(cps_model.state_dict(), f'cps_model_{seed}.pth')"]},{"cell_type":"markdown","metadata":{},"source":["## Task 5 - Error Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5510658,"sourceId":9127527,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
