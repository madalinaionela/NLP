{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:12:51.552279Z","iopub.status.busy":"2024-08-08T17:12:51.551985Z","iopub.status.idle":"2024-08-08T17:12:58.759777Z","shell.execute_reply":"2024-08-08T17:12:58.758839Z","shell.execute_reply.started":"2024-08-08T17:12:51.552253Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Device: cuda\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","#models\n","import torch\n","from transformers import AutoTokenizer, AutoModel\n","from transformers import EvalPrediction\n","from torch.utils.data import DataLoader, Dataset\n","from torch.nn import BCEWithLogitsLoss\n","from torch.optim import Adam\n","\n","#metrics\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.metrics import roc_curve, auc\n","\n","from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","print(f\"Device: {device}\")"]},{"cell_type":"markdown","metadata":{},"source":["## TASK 1 - CORPUS"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:13:02.417519Z","iopub.status.busy":"2024-08-08T17:13:02.417147Z","iopub.status.idle":"2024-08-08T17:13:02.425162Z","shell.execute_reply":"2024-08-08T17:13:02.424246Z","shell.execute_reply.started":"2024-08-08T17:13:02.417491Z"},"trusted":true},"outputs":[],"source":["def load_and_merge_data():\n","    \n","    #encodng the data into pandas.DataFrame objects\n","    url_a_test = '/kaggle/input/dataset/arguments-test.tsv'\n","    df_a_test = pd.read_csv(url_a_test, sep='\\t')\n","\n","    url_a_training = '/kaggle/input/dataset/arguments-training.tsv'\n","    df_a_training = pd.read_csv(url_a_training, sep='\\t')\n","\n","    url_a_validation = '/kaggle/input/dataset/arguments-validation.tsv'\n","    df_a_validation = pd.read_csv(url_a_validation, sep='\\t')\n","\n","    url_l_test = '/kaggle/input/dataset/labels-test.tsv'\n","    df_l_test = pd.read_csv(url_l_test, sep='\\t')\n","\n","    url_l_training = '/kaggle/input/dataset/labels-training.tsv'\n","    df_l_training = pd.read_csv(url_l_training, sep='\\t')\n","\n","    url_l_validation = '/kaggle/input/dataset/labels-validation.tsv'\n","    df_l_validation = pd.read_csv(url_l_validation, sep='\\t')\n","\n","    #merge argument dataframes with label dataframes\n","    df_test = pd.merge(df_a_test, df_l_test, on='Argument ID')\n","    df_training = pd.merge(df_a_training, df_l_training, on='Argument ID')\n","    df_validation = pd.merge(df_a_validation, df_l_validation, on='Argument ID')\n","\n","    return df_test, df_training, df_validation"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:13:07.779343Z","iopub.status.busy":"2024-08-08T17:13:07.778664Z","iopub.status.idle":"2024-08-08T17:13:07.943376Z","shell.execute_reply":"2024-08-08T17:13:07.942549Z","shell.execute_reply.started":"2024-08-08T17:13:07.779313Z"},"trusted":true},"outputs":[],"source":["df_test, df_training, df_validation = load_and_merge_data()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:13:11.539377Z","iopub.status.busy":"2024-08-08T17:13:11.538560Z","iopub.status.idle":"2024-08-08T17:13:11.571322Z","shell.execute_reply":"2024-08-08T17:13:11.570370Z","shell.execute_reply.started":"2024-08-08T17:13:11.539345Z"},"trusted":true},"outputs":[],"source":["def merge_and_drop_columns(df):\n","    # Merge level 2 annotations to level 3 categories\n","    df['Openess to change'] = df[['Self-direction: thought', 'Self-direction: action', 'Stimulation', 'Hedonism']].any(axis=1).astype(int)\n","    df['Self-enhancement'] = df[['Hedonism', 'Achievement', 'Power: dominance', 'Power: resources', 'Face']].any(axis=1).astype(int)\n","    df['Conservation'] = df[['Face', 'Security: personal', 'Security: societal', 'Tradition', 'Conformity: rules', 'Conformity: interpersonal', 'Humility']].any(axis=1).astype(int)\n","    df['Self-transcendence'] = df[['Humility', 'Benevolence: caring', 'Benevolence: dependability', 'Universalism: concern', 'Universalism: nature', 'Universalism: tolerance', 'Universalism: objectivity']].any(axis=1).astype(int)\n","    \n","    # Drop unuseful columns\n","    columns_to_drop = ['Argument ID', 'Self-direction: thought', 'Self-direction: action', 'Stimulation', 'Hedonism', 'Achievement', 'Power: dominance', 'Power: resources', 'Face', 'Security: personal', 'Security: societal', 'Tradition', 'Conformity: rules', 'Conformity: interpersonal', 'Humility', 'Benevolence: caring', 'Benevolence: dependability', 'Universalism: concern', 'Universalism: nature', 'Universalism: tolerance', 'Universalism: objectivity']\n","    df = df.drop(columns=columns_to_drop)\n","    \n","    return df\n","\n","df_test = merge_and_drop_columns(df_test)\n","df_training = merge_and_drop_columns(df_training)\n","df_validation = merge_and_drop_columns(df_validation)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:13:15.381703Z","iopub.status.busy":"2024-08-08T17:13:15.381346Z","iopub.status.idle":"2024-08-08T17:13:15.401378Z","shell.execute_reply":"2024-08-08T17:13:15.400503Z","shell.execute_reply.started":"2024-08-08T17:13:15.381673Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Conclusion</th>\n","      <th>Stance</th>\n","      <th>Premise</th>\n","      <th>Openess to change</th>\n","      <th>Self-enhancement</th>\n","      <th>Conservation</th>\n","      <th>Self-transcendence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>We should end affirmative action</td>\n","      <td>against</td>\n","      <td>affirmative action helps with employment equity.</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>We should end affirmative action</td>\n","      <td>in favor of</td>\n","      <td>affirmative action can be considered discrimin...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>We should ban naturopathy</td>\n","      <td>in favor of</td>\n","      <td>naturopathy is very dangerous for the most vul...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>We should prohibit women in combat</td>\n","      <td>in favor of</td>\n","      <td>women shouldn't be in combat because they aren...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>We should ban naturopathy</td>\n","      <td>in favor of</td>\n","      <td>once eradicated illnesses are returning due to...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                           Conclusion       Stance  \\\n","0    We should end affirmative action      against   \n","1    We should end affirmative action  in favor of   \n","2           We should ban naturopathy  in favor of   \n","3  We should prohibit women in combat  in favor of   \n","4           We should ban naturopathy  in favor of   \n","\n","                                             Premise  Openess to change  \\\n","0   affirmative action helps with employment equity.                  0   \n","1  affirmative action can be considered discrimin...                  0   \n","2  naturopathy is very dangerous for the most vul...                  0   \n","3  women shouldn't be in combat because they aren...                  0   \n","4  once eradicated illnesses are returning due to...                  0   \n","\n","   Self-enhancement  Conservation  Self-transcendence  \n","0                 1             1                   1  \n","1                 1             0                   1  \n","2                 1             1                   1  \n","3                 1             0                   0  \n","4                 1             1                   1  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df_test.head()"]},{"cell_type":"markdown","metadata":{},"source":["### DATA EXPLORATION\n","Ancora da inserire"]},{"cell_type":"markdown","metadata":{},"source":["### DATA PREPROCESSING"]},{"cell_type":"markdown","metadata":{},"source":["Encoding 'Stance' column into numerical format  "]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:13:19.276897Z","iopub.status.busy":"2024-08-08T17:13:19.275999Z","iopub.status.idle":"2024-08-08T17:13:19.294783Z","shell.execute_reply":"2024-08-08T17:13:19.293938Z","shell.execute_reply.started":"2024-08-08T17:13:19.276865Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_33/2140913224.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df_test['Stance'] = df_test['Stance'].replace({'in favor of': 1, 'against': 0}).astype(str)\n","/tmp/ipykernel_33/2140913224.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df_training['Stance'] = df_training['Stance'].replace({'in favor of': 1, 'against': 0}).astype(str)\n","/tmp/ipykernel_33/2140913224.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df_validation['Stance'] = df_validation['Stance'].replace({'in favor of': 1, 'against': 0}).astype(str)\n"]}],"source":["df_test['Stance'] = df_test['Stance'].replace({'in favor of': 1, 'against': 0}).astype(str)\n","df_training['Stance'] = df_training['Stance'].replace({'in favor of': 1, 'against': 0}).astype(str)\n","df_validation['Stance'] = df_validation['Stance'].replace({'in favor of': 1, 'against': 0}).astype(str)"]},{"cell_type":"markdown","metadata":{},"source":["Preparing data for tokenization input"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:13:22.648961Z","iopub.status.busy":"2024-08-08T17:13:22.648330Z","iopub.status.idle":"2024-08-08T17:13:22.656893Z","shell.execute_reply":"2024-08-08T17:13:22.655511Z","shell.execute_reply.started":"2024-08-08T17:13:22.648931Z"},"trusted":true},"outputs":[],"source":["labels_test = df_test.iloc[:, 3:7].values\n","labels_training = df_training.iloc[:, 3:7].values\n","labels_validation = df_validation.iloc[:, 3:7].values\n","\n","stance_test = df_test['Stance'].values\n","stance_training = df_training['Stance'].values\n","stance_validation = df_validation['Stance'].values"]},{"cell_type":"markdown","metadata":{},"source":["Tokenization process and creation of a dataset structure compatible with the bert model "]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:13:26.652388Z","iopub.status.busy":"2024-08-08T17:13:26.652038Z","iopub.status.idle":"2024-08-08T17:13:28.050862Z","shell.execute_reply":"2024-08-08T17:13:28.049916Z","shell.execute_reply.started":"2024-08-08T17:13:26.652362Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e4f7cd7d33df40c68840c53e1fdc228f","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"634a5566983c43419745ea9e8366b8e9","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"63f6312d73c143968aece33073e36a57","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b68836a29b74d9aa6a6bc5699698acb","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","max_length = 100\n","\n","class BertDatasetCreator(Dataset):\n","    def __init__(self, encodings, labels, tokenizer, max_length):\n","        self.encodings = encodings\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","    \n","    def __len__(self):\n","        return len(self.encodings)\n","    \n","    def __getitem__(self, idx):\n","        item = str(self.encodings[idx])\n","        item = ' '.join(item.split())\n","        \n","        encoded_dict = self.tokenizer.encode_plus(\n","            item,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            return_token_type_ids=True,\n","            truncation=True,\n","        )\n","        input_ids = encoded_dict['input_ids']\n","        attention_masks = encoded_dict['attention_mask']\n","        token_type_ids = encoded_dict['token_type_ids']\n","\n","        return {\n","            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n","            'attention_mask': torch.tensor(attention_masks, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'labels': torch.tensor(self.labels[idx], dtype=torch.float)\n","        }"]},{"cell_type":"markdown","metadata":{},"source":["#### Applying the BertDatasetCreator and preparing the datasets for the three different type of BERT models"]},{"cell_type":"markdown","metadata":{},"source":["##### BERT w/C dataset"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:13:31.806340Z","iopub.status.busy":"2024-08-08T17:13:31.805885Z","iopub.status.idle":"2024-08-08T17:13:31.812850Z","shell.execute_reply":"2024-08-08T17:13:31.811831Z","shell.execute_reply.started":"2024-08-08T17:13:31.806303Z"},"trusted":true},"outputs":[],"source":["test_dataset_c = BertDatasetCreator(df_test['Conclusion'], labels_test, tokenizer, max_length)\n","train_dataset_c = BertDatasetCreator(df_training['Conclusion'], labels_training, tokenizer, max_length)\n","val_dataset_c = BertDatasetCreator(df_validation['Conclusion'], labels_validation, tokenizer, max_length)"]},{"cell_type":"markdown","metadata":{},"source":["DataLoader definition - which will supply the data to the neural network in batches for efficient training and processing"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:13:37.829083Z","iopub.status.busy":"2024-08-08T17:13:37.828272Z","iopub.status.idle":"2024-08-08T17:13:37.833542Z","shell.execute_reply":"2024-08-08T17:13:37.832753Z","shell.execute_reply.started":"2024-08-08T17:13:37.829050Z"},"trusted":true},"outputs":[],"source":["batch_size = 16\n","test_dataloader_c = DataLoader(test_dataset_c, batch_size=batch_size)\n","train_dataloader_c = DataLoader(train_dataset_c, batch_size=batch_size)\n","val_dataloader_c = DataLoader(val_dataset_c, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["##### BERT w/CP"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:13:41.476367Z","iopub.status.busy":"2024-08-08T17:13:41.475612Z","iopub.status.idle":"2024-08-08T17:13:41.490005Z","shell.execute_reply":"2024-08-08T17:13:41.488704Z","shell.execute_reply.started":"2024-08-08T17:13:41.476326Z"},"trusted":true},"outputs":[],"source":["test_dataset_cp = BertDatasetCreator(df_test['Conclusion'] + ' ' + df_test['Premise'], labels_test, tokenizer, max_length)\n","train_dataset_cp = BertDatasetCreator(df_training['Conclusion'] + ' ' + df_training['Premise'], labels_training, tokenizer, max_length)\n","val_dataset_cp = BertDatasetCreator(df_validation['Conclusion'] + ' ' + df_validation['Premise'], labels_validation, tokenizer, max_length)\n","\n","test_dataloader_cp = DataLoader(test_dataset_cp, batch_size=batch_size)\n","train_dataloader_cp = DataLoader(train_dataset_cp, batch_size=batch_size)\n","val_dataloader_cp = DataLoader(val_dataset_cp, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["##### BERT w/CPS"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:13:45.306722Z","iopub.status.busy":"2024-08-08T17:13:45.306370Z","iopub.status.idle":"2024-08-08T17:13:45.321935Z","shell.execute_reply":"2024-08-08T17:13:45.320949Z","shell.execute_reply.started":"2024-08-08T17:13:45.306695Z"},"trusted":true},"outputs":[],"source":["test_dataset_cps = BertDatasetCreator(df_test['Conclusion'] + ' ' + df_test['Premise'] + ' ' + df_test['Stance'], labels_test, tokenizer, max_length)\n","train_dataset_cps = BertDatasetCreator(df_training['Conclusion'] + ' ' + df_training['Premise'] + ' ' + df_training['Stance'], labels_training, tokenizer, max_length)\n","val_dataset_cps = BertDatasetCreator(df_validation['Conclusion'] + ' ' + df_validation['Premise'] + ' ' + df_validation['Stance'], labels_validation, tokenizer, max_length)\n","\n","test_dataloader_cps = DataLoader(test_dataset_cps, batch_size=batch_size)\n","train_dataloader_cps = DataLoader(train_dataset_cps, batch_size=batch_size)\n","val_dataloader_cps = DataLoader(val_dataset_cps, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["## TASK 2 - MODEL DEFINITION"]},{"cell_type":"markdown","metadata":{},"source":["### BASELINE MODELS"]},{"cell_type":"markdown","metadata":{},"source":["Random uniform classifier"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_random_uniform_classifier(category):\n","    \"\"\"\n","    Creates a random classifier predicting 0 or 1 with uniform probability.\n","    inputs:\n","        category: Category to predict\n","    outputs: \n","        a function that generates random predictions\n","    \"\"\"\n","    def random_uniform_classifier(size):\n","        \"\"\"\n","        Generates random uniform predictions for the given category.\n","        inputs: \n","            size: number of predictions to generate\n","        outputs: \n","            array of random uniform predictions\n","        \"\"\"\n","        return np.random.choice([0, 1], size=size)\n","    \n","    return random_uniform_classifier"]},{"cell_type":"markdown","metadata":{},"source":["Majority classifier"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_majority_classifier(category, majority_value):\n","    \"\"\"\n","    Creates a majority classifier always predicting the most frequent valorization for the column.\n","    inputs:\n","        category: Category to predict\n","        majority_value: most frequent value (0 or 1)\n","    outputs:\n","        a function that generates majority predictions\n","    \"\"\"\n","    def majority_classifier(size):\n","        \"\"\"\n","        Generates majority predictions for the given category.\n","        inputs: \n","            size: number of predictions to generate\n","        outputs: \n","            array of majority predictions\n","        \"\"\"\n","        return np.full(size, majority_value)\n","    \n","    return majority_classifier"]},{"cell_type":"markdown","metadata":{},"source":["Creating the baseline models for every category and saving them in a classifiers dictionary"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["classifiers = {}\n","\n","categories = ['Openess to change', 'Self-enhancement', 'Conservation', 'Self-transcendence']\n","\n","#create classifiers for each category and save them in the dictionary\n","for category in categories:\n","    #random uniform classifier\n","    random_uniform_name = f'random_uniform_classifier_{category}'\n","    classifiers[random_uniform_name] = create_random_uniform_classifier(category)\n","\n","    #majority classifier\n","    majority_name = f'majority_classifier_{category}'\n","    classifiers[majority_name] = create_majority_classifier(category, majority_value=1) #da capire perchè majority_value=1"]},{"cell_type":"markdown","metadata":{},"source":["### BERT MODEL DEFINITION"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:14:14.110460Z","iopub.status.busy":"2024-08-08T17:14:14.109726Z","iopub.status.idle":"2024-08-08T17:14:14.117286Z","shell.execute_reply":"2024-08-08T17:14:14.116322Z","shell.execute_reply.started":"2024-08-08T17:14:14.110421Z"},"trusted":true},"outputs":[],"source":["class Bert_Model(torch.nn.Module):\n","    def __init__(self):\n","        super(Bert_Model, self).__init__()\n","        self.bert = AutoModel.from_pretrained(\n","            pretrained_model_name_or_path= 'bert-base-uncased', \n","            problem_type='multi_label_classification', \n","            num_labels = 4, \n","            return_dict=False)\n","        self.dropout = torch.nn.Dropout(p=0.3)\n","        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, 4)\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        _, outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        outputs = self.dropout(outputs)\n","        outputs = self.classifier(outputs)\n","        return outputs"]},{"cell_type":"markdown","metadata":{},"source":["#### Bert Models"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:14:16.770906Z","iopub.status.busy":"2024-08-08T17:14:16.770270Z","iopub.status.idle":"2024-08-08T17:14:20.907903Z","shell.execute_reply":"2024-08-08T17:14:20.906983Z","shell.execute_reply.started":"2024-08-08T17:14:16.770874Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a81d48fd55c447aa84d18ca28a040dd2","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["Bert_Model(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",")"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["c_model = Bert_Model()\n","cp_model = Bert_Model()\n","cps_model = Bert_Model()\n","\n","c_model.to(device)\n","cp_model.to(device)\n","cps_model.to(device)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:14:26.160881Z","iopub.status.busy":"2024-08-08T17:14:26.159994Z","iopub.status.idle":"2024-08-08T17:14:26.166942Z","shell.execute_reply":"2024-08-08T17:14:26.166056Z","shell.execute_reply.started":"2024-08-08T17:14:26.160847Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Bert_Model(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",")\n"]}],"source":["print(c_model)"]},{"cell_type":"markdown","metadata":{},"source":["## TASK 3 - METRICS"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:48:25.257298Z","iopub.status.busy":"2024-08-08T17:48:25.256921Z","iopub.status.idle":"2024-08-08T17:48:25.268690Z","shell.execute_reply":"2024-08-08T17:48:25.267690Z","shell.execute_reply.started":"2024-08-08T17:48:25.257264Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","def generate_classification_report(model, X_test, Y_test):\n","    \n","    # Mettere il modello in modalità di valutazione\n","    model.eval()\n","    Y_pred = []\n","    \n","    with torch.no_grad():# Disabilitare il calcolo dei gradienti per la valutazione\n","        for _, batch in enumerate(X_test, 0):\n","            input_ids = batch['input_ids'].to(device, dtype = torch.long)\n","            attention_mask = batch['attention_mask'].to(device, dtype = torch.long)\n","            token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n","            #labels = batch['labels'].to(device, dtype = torch.long)\n","            \n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        \n","        # Ottenere le predizioni\n","            preds = torch.argmax(outputs, dim=1)\n","            Y_pred.extend(preds.cpu().numpy())\n","    \n","    # Convertire Y_test in array multiclass se è multilabel\n","    if len(Y_test.shape) > 1 and Y_test.shape[1] > 1:\n","        Y_test = np.argmax(Y_test, axis=1)\n","    \n","    # Generare il classification report\n","    report = classification_report(Y_test, Y_pred, output_dict=True)\n","    \n","    # Mappatura delle labels\n","    label_names = {\n","        '0': \"Openness to change\",\n","        '1': \"Self-enhancement\",\n","        '2': \"Conservation\",\n","        '3': \"Self-transcendence\"\n","    }\n","    \n","    # Estrarre e stampare l'F1 score per ogni etichetta\n","    print(\"\\nF1 Scores per Label:\")\n","    for label, metrics in report.items():\n","        if label not in ['accuracy', 'macro avg', 'weighted avg']:\n","            label_name = label_names.get(label, f\"Label {label}\")\n","            f1_score = metrics['f1-score']\n","            print(f\"{label_name} F1: = {f1_score:.2f}\")\n","    \n","    # Estrarre e stampare il macro F1 score\n","    macro_f1_score = report['macro avg']['f1-score']\n","    print(f\"Macro F1 Score: {macro_f1_score:.2f}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## TASK 4 - TRAINING AND EVALUATION"]},{"cell_type":"markdown","metadata":{},"source":["Training process utils"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:14:40.656143Z","iopub.status.busy":"2024-08-08T17:14:40.655779Z","iopub.status.idle":"2024-08-08T17:14:41.478021Z","shell.execute_reply":"2024-08-08T17:14:41.477272Z","shell.execute_reply.started":"2024-08-08T17:14:40.656114Z"},"trusted":true},"outputs":[],"source":["#definition of the loss function\n","def loss_function(outputs, targets):\n","    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n","\n","#definition of the optimizers\n","optimizer = Adam(c_model.parameters(), lr = 1e-5)\n","\n","# Set seeds for reproducibility\n","def set_seed(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","\n","#seeds = [42, 123, 2024]\n","seeds = 456\n","set_seed(seeds)\n","\n","epochs = 2"]},{"cell_type":"markdown","metadata":{},"source":["Training function definition"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:21:19.933788Z","iopub.status.busy":"2024-08-08T17:21:19.932853Z","iopub.status.idle":"2024-08-08T17:21:19.941446Z","shell.execute_reply":"2024-08-08T17:21:19.940590Z","shell.execute_reply.started":"2024-08-08T17:21:19.933751Z"},"trusted":true},"outputs":[],"source":["def trainBert(model, dataloader, optimizer, loss_function):\n","    size = len(dataloader.dataset)\n","    model.train()\n","    running_loss = 0.0\n","    for batch, data in enumerate(dataloader, 0):\n","        ids = data['input_ids'].to(device, dtype=torch.long)\n","        mask = data['attention_mask'].to(device, dtype=torch.long)\n","        token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n","        labels = data['labels'].to(device)\n","        optimizer.zero_grad()\n","        outputs = model(ids, mask, token_type_ids)\n","    \n","        loss_value = loss_function(outputs, labels)\n","        loss_value.backward()\n","        optimizer.step()\n","        running_loss += loss_value.item()\n","        avg_train_loss = running_loss / len(dataloader)\n","  \n","        if batch % 100 == 0:\n","            current = batch * len(ids)\n","            print(f\"[{current:>5d}/{size:>5d}]\")\n","    \n","    return avg_train_loss"]},{"cell_type":"markdown","metadata":{},"source":["Validation function definition"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:14:51.072874Z","iopub.status.busy":"2024-08-08T17:14:51.072232Z","iopub.status.idle":"2024-08-08T17:14:51.084943Z","shell.execute_reply":"2024-08-08T17:14:51.083945Z","shell.execute_reply.started":"2024-08-08T17:14:51.072844Z"},"trusted":true},"outputs":[],"source":["\n","def validate_model(model, dataloader):\n","    model.eval()\n","    all_labels = []\n","    all_outputs = []\n","\n","    with torch.no_grad():\n","        for batch_idx, data in enumerate(dataloader, 0):\n","            input_ids = data['input_ids'].to(device, dtype = torch.long)\n","            attention_mask = data['attention_mask'].to(device, dtype = torch.long)\n","            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","            labels = data['labels'].to(device, dtype = torch.float)\n","            outputs = model(input_ids, attention_mask, token_type_ids)\n","            all_labels.extend(labels.cpu().numpy())\n","            all_outputs.extend(outputs.cpu().numpy())\n","\n","    all_labels = np.array(all_labels)\n","    all_outputs = np.array(all_outputs)\n","\n","    # Numero di etichette\n","    num_labels = all_labels.shape[1]\n","\n","    # Inizializza una lista per memorizzare le soglie ottimali per ogni etichetta\n","    optimal_thresholds = []\n","    auc_scores = []\n","\n","    for i in range(num_labels):\n","        # Calcola la curva ROC\n","        fpr, tpr, thresholds = roc_curve(all_labels[:, i], all_outputs[:, i])\n","        # Calcola l'AUC\n","        roc_auc = auc(fpr, tpr)\n","        auc_scores.append(roc_auc)\n","        # Trova la soglia che massimizza la somma di sensibilità e specificità\n","        optimal_idx = np.argmax(tpr - fpr)\n","        optimal_threshold = thresholds[optimal_idx]\n","        optimal_thresholds.append(optimal_threshold)\n","\n","    # Applica le soglie ottimali per ottenere le previsioni binarie\n","    all_preds = np.zeros_like(all_outputs)\n","    for i in range(num_labels):\n","        all_preds[:, i] = (all_outputs[:, i] > optimal_thresholds[i]).astype(int)\n","\n","    accuracy = accuracy_score(all_labels, all_preds)\n","    precision = precision_score(all_labels, all_preds, average='weighted')\n","    recall = recall_score(all_labels, all_preds, average='weighted')\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","     # Stampa le AUC per ogni etichetta\n","    for i, auc_score in enumerate(auc_scores):\n","        print(f'AUC for label {i}: {auc_score}')\n","\n","    return accuracy, precision, recall, f1, optimal_thresholds\n"]},{"cell_type":"markdown","metadata":{},"source":["#### TRAINING BERT W/C"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:21:29.047370Z","iopub.status.busy":"2024-08-08T17:21:29.046992Z","iopub.status.idle":"2024-08-08T17:24:41.303807Z","shell.execute_reply":"2024-08-08T17:24:41.302989Z","shell.execute_reply.started":"2024-08-08T17:21:29.047340Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1\n","-------------------------------\n","[    0/ 5393]\n","[ 1600/ 5393]\n","[ 3200/ 5393]\n","[ 4800/ 5393]\n","Loss: 0.5529\n","AUC for label 0: 0.6044386298080372\n","AUC for label 1: 0.6708891459482418\n","AUC for label 2: 0.547558264450479\n","AUC for label 3: 0.5373872033234582\n","Validation - Accuracy: 0.1551, Precision: 0.7111, Recall: 0.6241, F1 Score: 0.6453\n","Epoch 2\n","-------------------------------\n","[    0/ 5393]\n","[ 1600/ 5393]\n","[ 3200/ 5393]\n","[ 4800/ 5393]\n","Loss: 0.5475\n","AUC for label 0: 0.6045486508076976\n","AUC for label 1: 0.6832727008555606\n","AUC for label 2: 0.6025566231983528\n","AUC for label 3: 0.5633415057717845\n","Validation - Accuracy: 0.2173, Precision: 0.7281, Recall: 0.6704, F1 Score: 0.6915\n"]}],"source":["for epoch in range(epochs):\n","    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n","    avg_train_loss = trainBert(c_model, train_dataloader_c, optimizer, loss_function)\n","    print(f'Average Train Loss: {avg_train_loss:.4f}')\n","    #validation\n","    accuracy, precision, recall, f1, c_thresholds = validate_model(c_model, val_dataloader_c)\n","    print(f'Validation - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n","\n","torch.save(c_model.state_dict(), 'model.pthc')"]},{"cell_type":"markdown","metadata":{},"source":["Printing the classification_report for BERT w/C"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-08-08T17:47:29.153219Z","iopub.status.busy":"2024-08-08T17:47:29.152620Z","iopub.status.idle":"2024-08-08T17:47:36.827008Z","shell.execute_reply":"2024-08-08T17:47:36.826060Z","shell.execute_reply.started":"2024-08-08T17:47:29.153190Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","F1 Scores per Label:\n","Openness to change F1: = 0.00\n","Self-enhancement F1: = 0.09\n","Conservation F1: = 0.41\n","Self-transcendence F1: = 0.25\n","Macro F1 Score: 0.18694871993333806\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["generate_classification_report(c_model, test_dataloader_c, labels_test)"]},{"cell_type":"markdown","metadata":{},"source":["### TRAINING BERT W/CP"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T22:40:12.889978Z","iopub.status.busy":"2024-08-07T22:40:12.889591Z","iopub.status.idle":"2024-08-07T22:56:31.694351Z","shell.execute_reply":"2024-08-07T22:56:31.693270Z","shell.execute_reply.started":"2024-08-07T22:40:12.889947Z"},"trusted":true},"outputs":[],"source":["for epoch in range(epochs):\n","    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n","    avg_train_loss_cp = trainBert(cp_model, train_dataloader_cp, optimizer, loss_function)\n","    print(f'Loss: {avg_train_loss_cp:.4f}')\n","    #validation\n","    accuracy_cp, precision_cp, recall_cp, f1_cp, cp_thresholds = validate_model(cp_model, val_dataloader_cp)\n","    print(f'Validation - Accuracy: {accuracy_cp:.4f}, Precision: {precision_cp:.4f}, Recall: {recall_cp:.4f}, F1 Score: {f1_cp:.4f}')\n","\n","torch.save(cp_model.state_dict(), 'model.pthcp')"]},{"cell_type":"markdown","metadata":{},"source":["### TRAINING BERT W/CPS"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-07T22:57:05.384600Z","iopub.status.busy":"2024-08-07T22:57:05.383905Z","iopub.status.idle":"2024-08-07T23:13:24.362785Z","shell.execute_reply":"2024-08-07T23:13:24.361812Z","shell.execute_reply.started":"2024-08-07T22:57:05.384567Z"},"trusted":true},"outputs":[],"source":["for epoch in range(epochs):\n","    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n","    avg_train_loss_cps = trainBert(cps_model, train_dataloader_cps, optimizer, loss_function)\n","    print(f'Loss: {avg_train_loss_cps:.4f}')\n","    #validation\n","    accuracy_cps, precision_cps, recall_cps, f1_cps, cps_thresholds = validate_model(cps_model, val_dataloader_cps)\n","    print(f'Validation - Accuracy: {accuracy_cps:.4f}, Precision: {precision_cps:.4f}, Recall: {recall_cps:.4f}, F1 Score: {f1_cps:.4f}')\n","\n","torch.save(cps_model.state_dict(), 'model.pthcps')"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5510658,"sourceId":9127527,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
