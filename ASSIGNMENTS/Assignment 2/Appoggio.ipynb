{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_binary_classifier(category):\n",
    "    \"\"\"\n",
    "    Crea un classificatore binario casuale che predice solo la categoria specificata.\n",
    "\n",
    "    :param category: La categoria che il classificatore predir√†\n",
    "    :return: Una funzione che genera previsioni casuali della categoria specificata\n",
    "    \"\"\"\n",
    "    def random_binary_classifier(size):\n",
    "        \"\"\"\n",
    "        Genera previsioni casuali della categoria specificata.\n",
    "\n",
    "        :param size: Numero di previsioni da generare\n",
    "        :return: Array di previsioni casuali della categoria specificata\n",
    "        \"\"\"\n",
    "        return np.random.choice([0, 1], size=size)\n",
    "    \n",
    "    return random_binary_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    globals()[f'random_binary_classifier_{category}'] = create_random_binary_classifier(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    classifier = globals()[f'random_binary_classifier_{category}']\n",
    "    df_test[f'predicted_{category}'] = classifier(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(globals()[f'random_binary_classifier_Openess to change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating BERT_w/C classifiers for each category and saving them in the dictionary\n",
    "for category in categories:\n",
    "    bert_name = f'BERT_w/C_{category}'\n",
    "    classifiers[bert_name] = create_bert_classifier(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the BERT w_C classifiers to the test set\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    predictions = classifier(df_test['Conclusion'].tolist())\n",
    "    df_test[f'predicted_{classifier_name}'] = predictions\n",
    "\n",
    "print(df_test)\n",
    "\n",
    "#apply the BERT w_CPS classifiers to the test set WARNING: QUI SERVE DI CONVERTIRE IN LISTA ANCHE STANCE?\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    predictions = classifier(df_test['Conclusion'].tolist(), df_test['Premise'].tolist(), df_test['Stance'].tolist())\n",
    "    df_test[f'predicted_{classifier_name}'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating BERT_w/CP classifiers for each category and saving them in the dictionary\n",
    "for category in categories:\n",
    "    bert_name = f'BERT_w/CP_{category}'\n",
    "    classifiers[bert_name] = create_bert_classifier_with_premise(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create BERT_w/CPS classifiers for each category and save them in the dictionary\n",
    "for category in categories:\n",
    "    bert_name = f'BERT_w/CPS_{category}'\n",
    "    classifiers[bert_name] = create_bert_classifier_with_premise_and_stance(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "categories = ['category1', 'category2']  # Replace with actual categories\n",
    "y_true = {\n",
    "    'category': df_test['category'].tolist(),\n",
    "    'Stance': df_test['Stance_encoded'].tolist()\n",
    "}\n",
    "y_pred = [...]  # Replace with predicted labels\n",
    "\n",
    "# Calculate per-category F1 scores\n",
    "category_f1_scores = calculate_per_category_f1(y_true, y_pred, categories)\n",
    "\n",
    "# Calculate average F1 score\n",
    "average_f1 = calculate_average_f1(category_f1_scores)\n",
    "\n",
    "print(\"Per-category F1 scores:\", category_f1_scores)\n",
    "print(\"Average F1 score:\", average_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_dataset = TextDataset(train_texts, train_labels, tokenizer, max_len=128)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    # Train the model\n",
    "    train_bert_classifier(model, train_dataloader)\n",
    "\n",
    "    # Save the trained model in the dictionary\n",
    "    bert_name = f'BERT_w/CPS_{category}'\n",
    "    classifiers[bert_name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_bert_classifier(model, dataloader, epochs=3, lr=2e-5):\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            labels = batch['label']\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Create dataset and dataloader for validation\n",
    "    val_dataset = TextDataset(val_texts, val_labels, tokenizer, max_len=128)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            labels = batch['label']\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate per-category F1 scores\n",
    "    y_true = {\n",
    "        'category': [category] * len(val_labels),\n",
    "        'Stance': val_labels\n",
    "    }\n",
    "    category_f1_scores = calculate_per_category_f1(y_true, val_preds, [category])\n",
    "\n",
    "    # Print per-category F1 scores\n",
    "    print(f\"Per-category F1 scores for {category}:\", category_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Create the DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=data_collator)\n",
    "\n",
    "# Define a simple training loop\n",
    "def train_model(model, dataloader, epochs=3):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in dataloader:\n",
    "            inputs, labels = batch\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "# Assuming c_model, cp_model, and cps_model are already defined and initialized\n",
    "train_model(c_model, dataloader)\n",
    "train_model(cp_model, dataloader)\n",
    "train_model(cps_model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "\n",
    "    validation_y_true = df_validation[category]\n",
    "    test_y_true = df_test[category]\n",
    "    \n",
    "    y_pred_BERT_w_c = classifiers[f'BERT_w/C_{category}'](validation_conclusions)\n",
    "    \n",
    "    #applying the classifier to the test set\n",
    "    predictions = classifier(size=len(df_test))\n",
    "    \n",
    "    #saving the predictions in the test set\n",
    "    df_test[f'predicted_{classifier_name}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition of the model and application to the tokenized output of the Conclusion column\n",
    "\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    # Create the DataLoader\n",
    "    dataloader = DataLoader(df, batch_size=4, shuffle=True, collate_fn=data_collator)\n",
    "\n",
    "    # Iterate through the DataLoader\n",
    "    for batch in dataloader:\n",
    "        inputs, labels = batch\n",
    "        print(f\"Inputs: {inputs}\")\n",
    "        print(f\"Labels: {labels}\")\n",
    "        model_c = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        c_outputs = model_c(**c_inputs)\n",
    "        c_logits = c_outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining per-category F1 score metric\n",
    "def calculate_per_category_f1(y_true, y_pred, categories):\n",
    "    category_f1_scores = {}\n",
    "    for category in categories:\n",
    "        # Filter true and predicted labels for the current category\n",
    "        category_indices = [i for i, cat in enumerate(y_true['category']) if cat == category]\n",
    "        category_y_true = [y_true['Stance'][i] for i in category_indices]\n",
    "        category_y_pred = [y_pred[i] for i in category_indices]\n",
    "        \n",
    "        # Calculate F1 score for the current category\n",
    "        f1 = f1_score(category_y_true, category_y_pred, average='binary')\n",
    "        category_f1_scores[category] = f1\n",
    "    return category_f1_scores\n",
    "\n",
    "#defining macro F1 score metric\n",
    "def calculate_macro_f1(category_f1_scores):\n",
    "    average_f1 = np.mean(list(category_f1_scores.values()))\n",
    "    return average_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge level 2 annotations to level 3 categories\n",
    "\n",
    "df_test['Openess to change'] = df_test['Self-direction: thought'] | df_test['Self-direction: action'] | df_test['Stimulation'] | df_test['Hedonism'] \n",
    "df_test['Self-enhancement'] = df_test['Hedonism'] | df_test['Achievement'] | df_test['Power: dominance'] | df_test['Power: resources'] | df_test['Face']\n",
    "df_test['Conservation'] = df_test['Face'] | df_test['Security: personal'] | df_test['Security: societal'] | df_test['Tradition'] | df_test['Conformity: rules'] | df_test['Conformity: interpersonal'] | df_test['Humility']\n",
    "df_test['Self-transcendence'] = df_test['Humility'] | df_test['Benevolence: caring'] | df_test['Benevolence: dependability'] | df_test['Universalism: concern'] | df_test['Universalism: nature']| df_test['Universalism: tolerance'] | df_test['Universalism: objectivity']\n",
    "\n",
    "df_training['Openess to change'] = df_training['Self-direction: thought'] | df_training['Self-direction: action'] | df_training['Stimulation'] | df_training['Hedonism']\n",
    "df_training['Self-enhancement'] = df_training['Hedonism'] | df_training['Achievement'] | df_training['Power: dominance'] | df_training['Power: resources'] | df_training['Face']\n",
    "df_training['Conservation'] = df_training['Face'] | df_training['Security: personal'] | df_training['Security: societal'] | df_training['Tradition'] | df_training['Conformity: rules'] | df_training['Conformity: interpersonal'] | df_training['Humility']\n",
    "df_training['Self-transcendence'] = df_training['Humility'] | df_training['Benevolence: caring'] | df_training['Benevolence: dependability'] | df_training['Universalism: concern'] | df_training['Universalism: nature']| df_training['Universalism: tolerance'] | df_training['Universalism: objectivity']\n",
    "\n",
    "df_validation['Openess to change'] = df_validation['Self-direction: thought'] | df_validation['Self-direction: action'] | df_validation['Stimulation'] | df_validation['Hedonism']\n",
    "df_validation['Self-enhancement'] = df_validation['Hedonism'] | df_validation['Achievement'] | df_validation['Power: dominance'] | df_validation['Power: resources'] | df_validation['Face']\n",
    "df_validation['Conservation'] = df_validation['Face'] | df_validation['Security: personal'] | df_validation['Security: societal'] | df_validation['Tradition'] | df_validation['Conformity: rules'] | df_validation['Conformity: interpersonal'] | df_validation['Humility']\n",
    "df_validation['Self-transcendence'] = df_validation['Humility'] | df_validation['Benevolence: caring'] | df_validation['Benevolence: dependability'] | df_validation['Universalism: concern'] | df_validation['Universalism: nature']| df_validation['Universalism: tolerance'] | df_validation['Universalism: objectivity']\n",
    "\n",
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "max_length = 100\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenization(ds, stance, model_type):\n",
    "    # Initialize lists to store the results\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    token_type_ids = []\n",
    " \n",
    "    if model_type == 'c':\n",
    "        c_texts = ds['Conclusion']\n",
    "        \n",
    "        for text in c_texts:\n",
    "            encoded_dict = tokenizer.encode_plus(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=max_len,\n",
    "                padding='max_length',\n",
    "                return_token_type_ids=True,\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            input_ids.append(encoded_dict['input_ids'])\n",
    "            attention_masks.append(encoded_dict['attention_mask'])\n",
    "            token_type_ids.append(encoded_dict['token_type_ids'])\n",
    "            \n",
    "        # Convert lists to tensors\n",
    "        input_ids = torch.cat(input_ids, dim=0)\n",
    "        attention_masks = torch.cat(attention_masks, dim=0)\n",
    "        token_type_ids = torch.cat(token_type_ids, dim=0)\n",
    "\n",
    "        # Combine the results into a dictionary\n",
    "        df_c_inputs = {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_masks,\n",
    "            'token_type_ids': token_type_ids\n",
    "        }\n",
    "        return df_c_inputs\n",
    "    \n",
    "    elif model_type == 'cp':\n",
    "        # Extract the list of texts for tokenization of BERT_cp and BERT_cps model inputs\n",
    "        cp_texts = ds['Conclusion']+[\" \"]+ds['Premise']\n",
    "\n",
    "        for text in cp_texts:\n",
    "            encoded_dict = tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=max_len,\n",
    "                        padding='max_length',\n",
    "                        return_token_type_ids=True,\n",
    "                        truncation=True,\n",
    "                        return_attention_mask=True,\n",
    "                        return_tensors='pt'\n",
    "            )\n",
    "            input_ids.append(encoded_dict['input_ids'])\n",
    "            attention_masks.append(encoded_dict['attention_mask'])\n",
    "            token_type_ids.append(encoded_dict['token_type_ids'])\n",
    "\n",
    "        # Convert lists to tensors\n",
    "        input_ids = torch.cat(input_ids, dim=0)\n",
    "        attention_masks = torch.cat(attention_masks, dim=0)\n",
    "        token_type_ids = torch.cat(token_type_ids, dim=0)\n",
    "\n",
    "        # Combine the results into a dictionary\n",
    "        df_cp_inputs = {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_masks,\n",
    "            'token_type_ids': token_type_ids\n",
    "        }\n",
    "        return df_cp_inputs   \n",
    "    \n",
    "    elif model_type == 'cps': \n",
    "        # Extract the list of texts for tokenization of BERT_cp and BERT_cps model inputs\n",
    "        cps_texts = ds['Conclusion']+[\" \"]+ds['Premise']\n",
    "        stance = []\n",
    "\n",
    "        for text in cps_texts:\n",
    "            encoded_dict = tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=max_len,\n",
    "                        padding='max_length',\n",
    "                        return_token_type_ids=True,\n",
    "                        truncation=True,\n",
    "                        return_attention_mask=True,\n",
    "                        return_tensors='pt'\n",
    "            )\n",
    "            input_ids.append(encoded_dict['input_ids'])\n",
    "            attention_masks.append(encoded_dict['attention_mask'])\n",
    "            token_type_ids.append(encoded_dict['token_type_ids'])\n",
    "\n",
    "        # Convert lists to tensors\n",
    "        input_ids = torch.cat(input_ids, dim=0)\n",
    "        attention_masks = torch.cat(attention_masks, dim=0)\n",
    "        token_type_ids = torch.cat(token_type_ids, dim=0)\n",
    "        stance = torch.tensor(stance)\n",
    "\n",
    "        # Combine the results into a dictionary\n",
    "        df_cps_inputs = {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_masks,\n",
    "            'token_type_ids': token_type_ids,\n",
    "            'stance': stance\n",
    "        }\n",
    "        return df_cps_inputs   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_c = tokenization(ds_training, stance_training, 'c')\n",
    "train_dataset_cp = tokenization(ds_training, stance_training, 'cp')\n",
    "train_dataset_cps = tokenization(ds_training, stance_training, 'cps')\n",
    "\n",
    "val_dataset_c = tokenization(ds_validation, stance_validation, 'c')\n",
    "val_dataset_cp = tokenization(ds_validation, stance_validation, 'cp')\n",
    "val_dataset_cps = tokenization(ds_validation, stance_validation, 'cps')\n",
    "\n",
    "test_dataset_c = tokenization(ds_test, stance_test, 'c')\n",
    "test_dataset_cp = tokenization(ds_test, stance_test, 'cp')\n",
    "test_dataset_cps = tokenization(ds_test, stance_test, 'cps')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
